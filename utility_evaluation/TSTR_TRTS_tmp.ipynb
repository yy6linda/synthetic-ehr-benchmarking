{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, KFold\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from itertools import chain\n",
    "import lightgbm as lgb\n",
    "from scipy.misc import derivative\n",
    "from sklearn.metrics import average_precision_score\n",
    "import joblib\n",
    "import shap\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=2021, version=2)\n",
    "\n",
    "RUN_NUM = 3 # the number of synthetic datasets for each model\n",
    "RECALL_THRESHOLD = 0.6  # hold this to compute other threshold related metrics\n",
    "LABEL_INDEX = 5  # label column index in the dataset\n",
    "\n",
    "CAT_IDX = [int(ele) for ele in list(np.linspace(0, 2586, num=2587))]  # include race columns, no label\n",
    "RACE_COL = [0,1,2,3,4]\n",
    "CAT_IDX_wo_RACE_label = [int(ele) for ele in list(np.linspace(0, len(set(CAT_IDX)-set(RACE_COL))-1, len(set(CAT_IDX)-set(RACE_COL))))]\n",
    "COL_LIST = ['GENDER_SOURCE_VALUE',  'C008', 'C008.5', 'C008.52', 'C008.6', 'C010', 'C038', 'C038.1', 'C038.3', 'C041', 'C041.1', 'C041.11', 'C041.12', 'C041.2', 'C041.4', 'C041.8', 'C041.9', 'C053', 'C053.1', 'C054', 'C070', 'C070.2', 'C070.3', 'C070.4', 'C070.9', 'C071', 'C071.1', 'C078', 'C079', 'C079.2', 'C079.9', 'C080', 'C081', 'C090', 'C090.2', 'C1000', 'C1001', 'C1004', 'C1005', 'C1006', 'C1008', 'C1009', 'C1010', 'C1010.4', 'C1010.5', 'C1010.6', 'C1010.7', 'C1011', 'C1013', 'C1014', 'C1015', 'C1019', 'C1089', 'C1090', 'C110', 'C110.1', 'C110.11', 'C110.12', 'C110.13', 'C110.2', 'C112', 'C112.3', 'C117', 'C117.1', 'C130', 'C131', 'C132', 'C134', 'C136', 'C145', 'C149', 'C153', 'C153.2', 'C153.3', 'C158', 'C165', 'C165.1', 'C170', 'C170.1', 'C170.2', 'C172', 'C172.11', 'C172.2', 'C172.21', 'C172.22', 'C172.3', 'C173', 'C174', 'C174.1', 'C174.11', 'C175', 'C180', 'C180.3', 'C182', 'C184', 'C185', 'C189', 'C189.11', 'C189.21', 'C191', 'C193', 'C195', 'C195.1', 'C197', 'C198', 'C198.1', 'C198.2', 'C198.6', 'C199', 'C200', 'C201', 'C202', 'C202.2', 'C204', 'C204.11', 'C204.4', 'C208', 'C210', 'C211', 'C212', 'C213', 'C214', 'C214.1', 'C215', 'C216', 'C217', 'C217.1', 'C218', 'C218.1', 'C220', 'C221', 'C224', 'C224.1', 'C225', 'C225.1', 'C226', 'C227', 'C227.1', 'C227.3', 'C228', 'C228.1', 'C229', 'C240', 'C241', 'C241.1', 'C241.2', 'C242', 'C242.1', 'C242.3', 'C244', 'C244.1', 'C244.2', 'C244.4', 'C245', 'C245.21', 'C246', 'C246.7', 'C249', 'C250', 'C250.1', 'C250.12', 'C250.2', 'C250.22', 'C250.24', 'C250.25', 'C250.4', 'C250.41', 'C250.42', 'C250.5', 'C250.7', 'C251', 'C251.1', 'C252', 'C252.1', 'C253', 'C253.1', 'C253.2', 'C255', 'C255.21', 'C256', 'C256.4', 'C257', 'C257.1', 'C259', 'C259.3', 'C259.4', 'C260', 'C260.2', 'C260.3', 'C260.6', 'C261', 'C261.2', 'C261.4', 'C262', 'C263', 'C264', 'C264.1', 'C264.2', 'C264.3', 'C264.9', 'C269', 'C270', 'C270.32', 'C270.38', 'C271', 'C271.3', 'C272', 'C272.1', 'C272.11', 'C272.12', 'C272.13', 'C274', 'C274.1', 'C274.11', 'C274.21', 'C275', 'C275.1', 'C275.3', 'C275.51', 'C275.53', 'C275.6', 'C276', 'C276.1', 'C276.11', 'C276.12', 'C276.13', 'C276.14', 'C276.4', 'C276.41', 'C276.42', 'C276.5', 'C276.6', 'C276.8', 'C277', 'C277.4', 'C277.5', 'C277.7', 'C278', 'C278.1', 'C278.11', 'C278.3', 'C279', 'C279.1', 'C279.7', 'C280', 'C280.1', 'C280.2', 'C281', 'C281.12', 'C281.9', 'C282', 'C282.5', 'C282.8', 'C283', 'C284', 'C284.1', 'C285', 'C285.1', 'C285.2', 'C285.21', 'C285.22', 'C286', 'C286.3', 'C286.7', 'C286.81', 'C286.9', 'C287', 'C287.1', 'C287.3', 'C287.32', 'C288', 'C288.1', 'C288.11', 'C288.2', 'C289', 'C289.4', 'C289.5', 'C289.8', 'C290', 'C290.1', 'C290.2', 'C290.3', 'C291', 'C291.4', 'C291.8', 'C292', 'C292.1', 'C292.11', 'C292.12', 'C292.2', 'C292.3', 'C292.4', 'C292.5', 'C292.6', 'C293', 'C293.1', 'C295', 'C295.1', 'C296', 'C296.1', 'C296.22', 'C297', 'C297.1', 'C297.2', 'C300', 'C300.1', 'C300.11', 'C300.12', 'C300.13', 'C300.3', 'C300.4', 'C300.8', 'C300.9', 'C301', 'C302', 'C302.1', 'C303', 'C303.3', 'C303.4', 'C304', 'C305.2', 'C306', 'C306.1', 'C306.9', 'C312', 'C313', 'C313.1', 'C313.2', 'C313.3', 'C315', 'C315.1', 'C315.2', 'C315.3', 'C316', 'C316.1', 'C317', 'C317.1', 'C318', 'C320', 'C327', 'C327.1', 'C327.3', 'C327.31', 'C327.32', 'C327.4', 'C327.41', 'C327.5', 'C327.6', 'C327.7', 'C327.71', 'C331', 'C331.1', 'C331.9', 'C332', 'C333', 'C333.1', 'C333.4', 'C334', 'C335', 'C337', 'C338', 'C338.1', 'C338.2', 'C339', 'C340', 'C340.1', 'C341', 'C342', 'C343', 'C344', 'C345', 'C345.1', 'C345.11', 'C345.12', 'C345.3', 'C346', 'C346.1', 'C346.3', 'C347', 'C348', 'C348.2', 'C348.7', 'C348.8', 'C348.9', 'C349', 'C350', 'C350.1', 'C350.2', 'C350.3', 'C350.6', 'C351', 'C352', 'C352.1', 'C352.2', 'C353', 'C353.1', 'C355', 'C355.1', 'C356', 'C357', 'C358', 'C359', 'C359.2', 'C360', 'C360.2', 'C361', 'C362', 'C362.21', 'C362.23', 'C362.26', 'C362.27', 'C362.29', 'C362.3', 'C362.4', 'C362.6', 'C362.9', 'C363', 'C363.3', 'C364', 'C364.1', 'C364.51', 'C365', 'C365.1', 'C365.11', 'C365.2', 'C366', 'C366.2', 'C367', 'C367.1', 'C367.2', 'C367.4', 'C367.8', 'C367.9', 'C368', 'C368.1', 'C368.2', 'C368.3', 'C368.4', 'C368.9', 'C369', 'C369.2', 'C369.5', 'C370', 'C370.1', 'C370.31', 'C371', 'C371.1', 'C371.2', 'C371.21', 'C371.3', 'C372', 'C374', 'C374.3', 'C374.6', 'C375', 'C375.1', 'C375.2', 'C377', 'C377.1', 'C377.3', 'C378', 'C378.1', 'C378.2', 'C379', 'C379.1', 'C379.2', 'C379.5', 'C379.9', 'C380', 'C380.1', 'C380.4', 'C381', 'C381.1', 'C381.11', 'C381.2', 'C381.9', 'C382', 'C383', 'C384', 'C384.4', 'C385', 'C385.3', 'C386', 'C386.1', 'C386.2', 'C386.21', 'C386.3', 'C386.9', 'C388', 'C389', 'C389.1', 'C389.2', 'C389.4', 'C389.5', 'C394', 'C394.1', 'C394.2', 'C394.7', 'C395', 'C395.1', 'C395.2', 'C395.3', 'C395.4', 'C395.6', 'C396', 'C401', 'C401.1', 'C401.2', 'C401.21', 'C401.22', 'C401.3', 'C411', 'C411.1', 'C411.2', 'C411.3', 'C411.4', 'C411.8', 'C414', 'C415', 'C415.11', 'C415.2', 'C416', 'C418', 'C418.1', 'C420', 'C420.2', 'C420.3', 'C425', 'C425.1', 'C425.12', 'C426', 'C426.21', 'C426.24', 'C426.31', 'C426.32', 'C426.7', 'C426.8', 'C427', 'C427.11', 'C427.12', 'C427.21', 'C427.22', 'C427.3', 'C427.5', 'C427.6', 'C427.61', 'C427.7', 'C427.8', 'C427.9', 'C428', 'C428.1', 'C428.2', 'C428.3', 'C428.4', 'C429', 'C429.1', 'C429.2', 'C429.3', 'C430', 'C430.2', 'C433', 'C433.1', 'C433.11', 'C433.2', 'C433.21', 'C433.3', 'C433.31', 'C433.5', 'C433.8', 'C440', 'C440.9', 'C441', 'C442', 'C442.1', 'C442.11', 'C443', 'C443.1', 'C443.9', 'C444', 'C446', 'C447', 'C447.7', 'C450', 'C451', 'C452', 'C452.2', 'C454', 'C454.1', 'C454.11', 'C455', 'C456', 'C458', 'C458.1', 'C458.2', 'C458.9', 'C459', 'C459.1', 'C459.9', 'C464', 'C465', 'C465.2', 'C465.4', 'C470', 'C471', 'C472', 'C473', 'C473.3', 'C473.4', 'C474', 'C474.1', 'C474.2', 'C475', 'C475.9', 'C476', 'C477', 'C478', 'C479', 'C480', 'C480.1', 'C480.11', 'C480.2', 'C480.5', 'C481', 'C483', 'C495', 'C495.2', 'C496', 'C496.1', 'C496.2', 'C496.21', 'C496.3', 'C497', 'C498', 'C500', 'C501', 'C502', 'C503', 'C504', 'C505', 'C506', 'C507', 'C508', 'C509', 'C509.1', 'C509.2', 'C509.8', 'C510', 'C512', 'C512.1', 'C512.2', 'C512.7', 'C512.8', 'C512.9', 'C513', 'C513.3', 'C513.31', 'C513.4', 'C513.8', 'C514', 'C514.1', 'C514.2', 'C516', 'C516.1', 'C519', 'C519.1', 'C519.8', 'C519.9', 'C520', 'C520.2', 'C521', 'C521.1', 'C522', 'C522.5', 'C523', 'C523.1', 'C523.3', 'C523.32', 'C524', 'C524.3', 'C525', 'C525.1', 'C526', 'C526.41', 'C526.42', 'C527', 'C527.2', 'C527.7', 'C528', 'C528.11', 'C528.12', 'C528.3', 'C528.5', 'C529', 'C530', 'C530.1', 'C530.11', 'C530.12', 'C530.13', 'C530.14', 'C530.15', 'C530.2', 'C530.3', 'C530.5', 'C530.9', 'C531', 'C531.1', 'C531.2', 'C531.3', 'C531.4', 'C532', 'C535', 'C535.1', 'C535.2', 'C535.6', 'C535.8', 'C535.9', 'C536', 'C536.3', 'C536.7', 'C536.8', 'C537', 'C539', 'C540', 'C540.11', 'C550', 'C550.1', 'C550.2', 'C550.4', 'C550.5', 'C550.6', 'C555', 'C555.1', 'C555.2', 'C555.21', 'C556', 'C556.1', 'C557', 'C557.1', 'C558', 'C559', 'C560', 'C560.1', 'C560.2', 'C560.4', 'C561', 'C561.1', 'C561.2', 'C562', 'C562.1', 'C562.2', 'C563', 'C564', 'C564.1', 'C564.8', 'C565', 'C565.1', 'C567', 'C568', 'C568.1', 'C569', 'C569.1', 'C569.2', 'C571', 'C571.5', 'C571.51', 'C571.8', 'C571.81', 'C572', 'C573', 'C573.2', 'C573.3', 'C573.4', 'C573.5', 'C573.6', 'C573.7', 'C574', 'C574.1', 'C574.11', 'C574.12', 'C574.2', 'C574.3', 'C575', 'C575.2', 'C575.7', 'C575.8', 'C575.9', 'C577', 'C577.1', 'C577.2', 'C577.3', 'C578', 'C578.1', 'C578.2', 'C578.8', 'C578.9', 'C579', 'C579.2', 'C579.8', 'C580', 'C580.2', 'C580.32', 'C580.4', 'C585', 'C585.1', 'C585.2', 'C585.3', 'C585.32', 'C585.33', 'C585.34', 'C585.4', 'C586', 'C586.2', 'C586.4', 'C587', 'C588', 'C588.1', 'C588.2', 'C589', 'C590', 'C591', 'C592', 'C592.1', 'C592.11', 'C592.13', 'C593', 'C593.1', 'C593.2', 'C594', 'C594.1', 'C594.3', 'C595', 'C596', 'C596.5', 'C597', 'C597.1', 'C597.2', 'C598', 'C598.9', 'C599', 'C599.1', 'C599.2', 'C599.3', 'C599.4', 'C599.5', 'C599.6', 'C599.8', 'C599.9', 'C600', 'C601', 'C601.1', 'C601.11', 'C601.3', 'C602', 'C603', 'C603.1', 'C604', 'C604.1', 'C605', 'C608', 'C609', 'C610', 'C610.1', 'C610.2', 'C610.3', 'C610.4', 'C610.8', 'C611', 'C611.1', 'C611.11', 'C611.3', 'C612', 'C612.2', 'C613', 'C613.1', 'C613.5', 'C613.7', 'C613.8', 'C613.9', 'C614', 'C614.1', 'C614.32', 'C614.33', 'C614.4', 'C614.51', 'C614.52', 'C614.54', 'C615', 'C617', 'C618', 'C618.1', 'C618.2', 'C619', 'C619.1', 'C619.2', 'C619.3', 'C619.4', 'C619.5', 'C621', 'C622', 'C622.1', 'C622.2', 'C623', 'C624', 'C624.9', 'C625', 'C625.1', 'C626', 'C626.1', 'C626.11', 'C626.12', 'C626.13', 'C626.14', 'C626.15', 'C626.2', 'C626.8', 'C627', 'C627.1', 'C627.2', 'C627.3', 'C627.4', 'C627.5', 'C628', 'C634', 'C634.1', 'C635', 'C635.2', 'C635.3', 'C636', 'C636.1', 'C636.3', 'C637', 'C638', 'C642', 'C642.1', 'C643', 'C644', 'C645', 'C646', 'C647', 'C647.1', 'C649', 'C649.1', 'C650', 'C651', 'C652', 'C653', 'C654.1', 'C654.2', 'C655', 'C655.1', 'C656', 'C656.2', 'C656.26', 'C656.3', 'C656.7', 'C656.8', 'C657', 'C658', 'C661', 'C663', 'C665', 'C669', 'C671', 'C674', 'C676', 'C681', 'C681.1', 'C681.2', 'C681.3', 'C681.5', 'C681.7', 'C686', 'C686.1', 'C686.2', 'C686.3', 'C686.4', 'C687', 'C687.1', 'C687.2', 'C687.3', 'C687.4', 'C689', 'C690', 'C690.1', 'C691', 'C694', 'C694.1', 'C694.2', 'C695', 'C695.3', 'C695.42', 'C695.7', 'C695.8', 'C695.9', 'C696', 'C696.3', 'C696.41', 'C696.42', 'C697', 'C698', 'C700', 'C701', 'C701.1', 'C701.2', 'C701.3', 'C701.4', 'C701.5', 'C701.6', 'C702', 'C702.1', 'C702.2', 'C703', 'C703.1', 'C704', 'C704.1', 'C704.12', 'C704.2', 'C704.8', 'C705', 'C705.1', 'C705.3', 'C705.8', 'C706', 'C706.1', 'C706.2', 'C706.8', 'C707', 'C707.1', 'C707.2', 'C707.3', 'C709', 'C709.2', 'C709.7', 'C710', 'C710.19', 'C711', 'C711.1', 'C712', 'C714', 'C714.1', 'C715', 'C715.1', 'C715.2', 'C715.3', 'C716', 'C716.9', 'C717', 'C720', 'C720.1', 'C721', 'C721.1', 'C721.2', 'C721.8', 'C722', 'C722.1', 'C722.6', 'C722.7', 'C722.8', 'C722.9', 'C723', 'C723.1', 'C724', 'C724.8', 'C724.9', 'C726', 'C726.1', 'C726.2', 'C726.3', 'C726.4', 'C727', 'C727.1', 'C727.2', 'C727.4', 'C727.5', 'C727.6', 'C727.8', 'C728', 'C728.2', 'C728.7', 'C728.71', 'C729', 'C729.3', 'C731', 'C732', 'C732.1', 'C733', 'C733.2', 'C733.4', 'C733.6', 'C733.8', 'C733.9', 'C735', 'C735.1', 'C735.21', 'C735.23', 'C735.3', 'C736', 'C736.2', 'C737', 'C737.1', 'C737.3', 'C738', 'C738.4', 'C739', 'C740', 'C740.1', 'C740.11', 'C740.12', 'C740.2', 'C740.3', 'C740.9', 'C741', 'C741.2', 'C741.3', 'C741.4', 'C742', 'C742.1', 'C742.2', 'C742.8', 'C742.9', 'C743', 'C743.11', 'C743.2', 'C743.21', 'C743.4', 'C743.9', 'C745', 'C747', 'C747.1', 'C747.11', 'C747.12', 'C747.13', 'C747.2', 'C748', 'C749', 'C750', 'C750.13', 'C750.21', 'C751', 'C751.12', 'C751.2', 'C751.21', 'C751.22', 'C752', 'C752.2', 'C753', 'C754', 'C755', 'C755.1', 'C755.61', 'C756', 'C756.3', 'C756.5', 'C758', 'C758.1', 'C759', 'C760', 'C761', 'C763', 'C764', 'C765', 'C766', 'C769', 'C770', 'C771', 'C771.1', 'C771.2', 'C772', 'C772.1', 'C772.2', 'C772.3', 'C772.4', 'C772.6', 'C773', 'C780', 'C781', 'C781.2', 'C782', 'C782.3', 'C782.6', 'C783', 'C783.1', 'C785', 'C788', 'C789', 'C790', 'C790.1', 'C790.6', 'C790.8', 'C792', 'C792.1', 'C793', 'C793.2', 'C794', 'C795', 'C796', 'C797', 'C798', 'C798.1', 'C800', 'C800.1', 'C800.2', 'C800.3', 'C801', 'C802', 'C803', 'C803.1', 'C803.2', 'C803.3', 'C804', 'C805', 'C807', 'C809', 'C817', 'C818', 'C819', 'C830', 'C835', 'C840', 'C840.3', 'C841', 'C842', 'C850', 'C851', 'C854', 'C857', 'C858', 'C859', 'C870', 'C870.1', 'C870.3', 'C870.5', 'C871', 'C871.1', 'C871.2', 'C871.3', 'C871.4', 'C872', 'C873', 'C907', 'C911', 'C912', 'C913', 'C915', 'C916', 'C930', 'C931', 'C938', 'C938.1', 'C938.2', 'C939', 'C946', 'C947', 'C949', 'C949.1', 'C952', 'C958', 'C960', 'C961', 'C963', 'C963.1', 'C965', 'C969', 'C972', 'C979', 'C990', 'C994', 'C994.1', 'C994.2', 'C994.21', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P26', 'P27', 'P28', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35', 'P36', 'P37', 'P38', 'P39', 'P40', 'P41', 'P42', 'P49', 'P51', 'P52', 'P55', 'P57', 'P59', 'P62', 'P64', 'P66', 'P67', 'P68', 'P69', 'P70', 'P71', 'P72', 'P73', 'P74', 'P75', 'P76', 'P77', 'P78', 'P79', 'P80', 'P81', 'P82', 'P83', 'P86', 'P89', 'P90', 'P91', 'P92', 'P93', 'P94', 'P95', 'P96', 'P97', 'P102', 'P105', 'P106', 'P107', 'P108', 'P109', 'P111', 'P112', 'I1001', 'I1005921', 'I1005931', 'I10154', 'I10156', 'I10167', 'I10169', 'I10180', 'I10184', 'I10223', 'I1025342', 'I103', 'I10324', 'I10355', 'I10368', 'I1037042', 'I10379', 'I10391', 'I10395', 'I1040028', 'I10402', 'I10454', 'I10528', 'I105669', 'I105694', 'I10572', 'I10582', 'I10600', 'I10612', 'I106212', 'I10627', 'I106467', 'I10689', 'I10691', 'I10737', 'I10753', 'I10759', 'I10763', 'I10767', 'I108088', 'I108118', 'I10814', 'I10829', 'I1086769', 'I10869', 'I10898', 'I10908', 'I1091', 'I10962', 'I10975', 'I11002', 'I1100699', 'I11124', 'I1114195', 'I1114883', 'I11149', 'I1116632', 'I1116738', 'I11170', 'I11177', 'I11202', 'I11246', 'I11248', 'I11251', 'I11253', 'I11256', 'I11258', 'I11289', 'I11295', 'I11359', 'I11413', 'I11416', 'I114189', 'I114200', 'I114202', 'I114228', 'I11423', 'I114265', 'I114398', 'I114477', 'I114979', 'I1151', 'I115264', 'I115552', 'I115698', 'I11636', 'I117055', 'I1191', 'I119565', 'I1202', 'I121047', 'I121191', 'I1223', 'I1244014', 'I125464', 'I1256', 'I125933', 'I1272', 'I128790', 'I128793', 'I1291', 'I1292', 'I1292422', 'I1299884', 'I1300786', 'I1303851', 'I1303855', 'I1304122', 'I1305637', 'I1306284', 'I1307106', 'I1307404', 'I1309229', 'I1309239', 'I1309250', 'I1309373', 'I1310171', 'I1310587', 'I1310635', 'I1311067', 'I1311500', 'I1311569', 'I1314221', 'I1314612', 'I131725', 'I1331', 'I134615', 'I1347', 'I134774', 'I135391', 'I135447', 'I135775', 'I1358965', 'I1358966', 'I1358977', 'I1359', 'I136198', 'I136411', 'I1364291', 'I1364430', 'I1370574', 'I1370773', 'I1372704', 'I1373458', 'I1378', 'I1390', 'I139462', 'I139825', 'I1399', 'I140587', 'I141366', 'I141626', 'I1418', 'I142131', 'I1424', 'I142407', 'I142438', 'I1424884', 'I1426331', 'I1426598', 'I1426890', 'I1427022', 'I1427085', 'I1427088', 'I1433693', 'I1433868', 'I1441660', 'I144254', 'I1455099', 'I14584', 'I1483317', 'I1484911', 'I1488564', 'I1489914', 'I151317', 'I151392', 'I151399', 'I1514', 'I151558', 'I151578', 'I151692', 'I151827', 'I151875', 'I151889', 'I152001', 'I152218', 'I152413', 'I152490', 'I152523', 'I152535', 'I152633', 'I152699', 'I152951', 'I153010', 'I153101', 'I153165', 'I153184', 'I153592', 'I153668', 'I153736', 'I1538097', 'I153889', 'I153970', 'I153974', 'I1545653', 'I1546438', 'I1546451', 'I154990', 'I155046', 'I1551291', 'I15657', 'I1588', 'I1592257', 'I1596', 'I1596450', 'I1596930', 'I1596931', 'I1596932', 'I1596933', 'I1596934', 'I15996', 'I1605101', 'I16054', 'I161', 'I164', 'I1656328', 'I1657128', 'I1657131', 'I1657134', 'I1665684', 'I167', 'I1670007', 'I168', 'I1712', 'I17128', 'I1721603', 'I17300', 'I1731071', 'I174742', 'I175184', 'I1767', 'I17767', 'I1801820', 'I1808', 'I1815', 'I1819', 'I1827', 'I1841', 'I18603', 'I18631', 'I187832', 'I1886', 'I18867', 'I1894', 'I1895', 'I1897', 'I18993', 'I1901', 'I190283', 'I190376', 'I190465', 'I190521', 'I1908', 'I19143', 'I191831', 'I1919', 'I19478', 'I19484', 'I195085', 'I1952', 'I19552', 'I196102', 'I196458', 'I196463', 'I196472', 'I196474', 'I196476', 'I196498', 'I196502', 'I196503', 'I19698', 'I197', 'I197116', 'I19737', 'I19831', 'I19860', 'I19861', 'I1986821', 'I1991302', 'I1992', 'I1998', 'I1999660', 'I2002', 'I20063', 'I2019', 'I202363', 'I202421', 'I202433', 'I202462', 'I202472', 'I202479', 'I202488', 'I202525', 'I202559', 'I202585', 'I202619', 'I202702', 'I202813', 'I202862', 'I202866', 'I202869', 'I202888', 'I202896', 'I202927', 'I202941', 'I202955', 'I202961', 'I202976', 'I202991', 'I202998', 'I203012', 'I203018', 'I203167', 'I203169', 'I2032', 'I203219', 'I203302', 'I203333', 'I203344', 'I203345', 'I2034', 'I203457', 'I20352', 'I203546', 'I203565', 'I203576', 'I203600', 'I203680', 'I203729', 'I203791', 'I204315', 'I2045613', 'I20481', 'I20489', 'I2051', 'I2058846', 'I20610', 'I2062', 'I2101', 'I21032', 'I21090', 'I21183', 'I21212', 'I21232', 'I21241', 'I21254', 'I21406', 'I214342', 'I214354', 'I214549', 'I214555', 'I214824', 'I215098', 'I215101', 'I215510', 'I215741', 'I215850', 'I215926', 'I215927', 'I215928', 'I216201', 'I216221', 'I216459', 'I216652', 'I216653', 'I216878', 'I216971', 'I217020', 'I217152', 'I217681', 'I2177', 'I217713', 'I217852', 'I217956', 'I217992', 'I2180', 'I218002', 'I218003', 'I218093', 'I218248', 'I21842', 'I218772', 'I218860', 'I2189', 'I218959', 'I218986', 'I2191', 'I219114', 'I219298', 'I2193', 'I219301', 'I219356', 'I219362', 'I2194', 'I21949', 'I219740', 'I219866', 'I220220', 'I220224', 'I220343', 'I220458', 'I220508', 'I220577', 'I220581', 'I220606', 'I220778', 'I221144', 'I221147', 'I22299', 'I2231', 'I224891', 'I224913', 'I224920', 'I224921', 'I224938', 'I224954', 'I225036', 'I225037', 'I22656', 'I226718', 'I22696', 'I22701', 'I227591', 'I227682', 'I227730', 'I227743', 'I228476', 'I2286', 'I228783', 'I228790', 'I22892', 'I23043', 'I231049', 'I232540', 'I233698', 'I234449', 'I235273', 'I235473', 'I235496', 'I2356', 'I235618', 'I235786', 'I2358', 'I236693', 'I236719', 'I236778', 'I236809', 'I237159', 'I23742', 'I23744', 'I2382', 'I2393', 'I2396', 'I2400', 'I2403', 'I2409', 'I2418', 'I2447', 'I24591', 'I24605', 'I2473', 'I24853', 'I24909', 'I24941', 'I24942', 'I24947', 'I25025', 'I25033', 'I25037', 'I25120', 'I25126', 'I25138', 'I25255', 'I253182', 'I253337', 'I2541', 'I25480', 'I2551', 'I2555', 'I2556', 'I25789', 'I2582', 'I258494', 'I2590', 'I2596', 'I2598', 'I2599', 'I260101', 'I261547', 'I261551', 'I261575', 'I261624', 'I261657', 'I261680', 'I262150', 'I26225', 'I2623', 'I26237', 'I2653', 'I265323', 'I2670', 'I2683', 'I2685', 'I27084', 'I2709', 'I27169', 'I27334', 'I273888', 'I274332', 'I274783', 'I274964', 'I275635', 'I275891', 'I276237', 'I278567', 'I27863', 'I27946', 'I279645', 'I28031', 'I281', 'I282381', 'I283579', 'I2837', 'I283742', 'I283753', 'I283809', 'I283810', 'I283838', 'I28439', 'I284637', 'I284704', 'I284799', 'I284870', 'I285077', 'I285245', 'I2878', 'I28874', 'I28889', 'I2890', 'I29008', 'I29046', 'I29155', 'I29268', 'I29365', 'I29421', 'I2955', 'I29561', 'I296', 'I29787', 'I298665', 'I298869', 'I3001', 'I300195', 'I3002', 'I3008', 'I30125', 'I3013', 'I301542', 'I301543', 'I302379', 'I303263', 'I3041', 'I306674', 'I3108', 'I3129', 'I3143', 'I31448', 'I314605', 'I314684', 'I31555', 'I319864', 'I31994', 'I320864', 'I321064', 'I321876', 'I321952', 'I321988', 'I322167', 'I324026', 'I3251', 'I3254', 'I3255', 'I325642', 'I325887', 'I32613', 'I32624', 'I326374', 'I3264', 'I32675', 'I327148', 'I327361', 'I3274', 'I327503', 'I3288', 'I3289', 'I32915', 'I32937', 'I32968', 'I3310', 'I33199', 'I332', 'I3322', 'I33290', 'I33408', 'I3355', 'I3356', 'I3361', 'I33738', 'I337623', 'I338036', 'I3407', 'I341248', 'I3418', 'I3423', 'I3429', 'I34296', 'I34316', 'I34322', 'I34347', 'I3435', 'I3443', 'I3444', 'I34693', 'I34905', 'I3498', 'I3500', 'I350202', 'I35208', 'I3521', 'I352372', 'I352385', 'I352393', 'I352741', 'I352777', 'I352951', 'I35296', 'I35302', 'I353062', 'I353099', 'I353102', 'I35465', 'I35619', 'I35629', 'I35636', 'I356887', 'I35780', 'I358255', 'I358263', 'I35827', 'I35829', 'I358859', 'I360262', 'I36117', 'I36122', 'I3616', 'I3628', 'I36344', 'I36345', 'I3638', 'I36387', 'I3639', 'I3640', 'I3642', 'I36437', 'I3648', 'I36567', 'I36676', 'I36709', 'I36721', 'I36726', 'I37255', 'I37415', 'I37418', 'I3743', 'I376', 'I37617', 'I37798', 'I37801', 'I37806', 'I37925', 'I37935', 'I3827', 'I38400', 'I38404', 'I38413', 'I386938', 'I3966', 'I39786', 'I398335', 'I3992', 'I39935', 'I39952', 'I39954', 'I39993', 'I39998', 'I40048', 'I40114', 'I4018', 'I40254', 'I404925', 'I404930', 'I404964', 'I4053', 'I405392', 'I40790', 'I407990', 'I4083', 'I4099', 'I4100', 'I41126', 'I41127', 'I41208', 'I4124', 'I41493', 'I4179', 'I42316', 'I42331', 'I42347', 'I42351', 'I42355', 'I42372', 'I42375', 'I42463', 'I42543', 'I42568', 'I42612', 'I4278', 'I42781', 'I42844', 'I42954', 'I42955', 'I4301', 'I4316', 'I433', 'I4337', 'I435', 'I43611', 'I4385', 'I4419', 'I4441', 'I4450', 'I4452', 'I4462', 'I4477', 'I448', 'I4491', 'I4492', 'I4493', 'I4508', 'I4511', 'I460132', 'I4603', 'I46041', 'I461016', 'I46241', 'I4719', 'I473387', 'I47579', 'I475968', 'I47613', 'I47686', 'I477053', 'I4815', 'I48203', 'I4821', 'I482574', 'I4832', 'I484348', 'I4845', 'I4850', 'I486826', 'I48937', 'I4910', 'I4917', 'I4919', 'I49276', 'I492810', 'I4952', 'I495430', 'I49670', 'I49737', 'I4986', 'I5021', 'I5032', 'I508', 'I5093', 'I51272', 'I51428', 'I51670', 'I519', 'I52175', 'I52177', 'I5224', 'I52356', 'I52358', 'I52364', 'I5240', 'I52440', 'I52582', 'I52769', 'I5281', 'I5333', 'I539812', 'I540404', 'I542941', 'I544165', 'I5470', 'I5487', 'I5489', 'I5492', 'I54987', 'I5499', 'I54993', 'I55018', 'I55024', 'I5509', 'I5521', 'I5531', 'I5553', 'I5640', 'I56443', 'I56466', 'I56476', 'I56512', 'I5666', 'I56795', 'I569', 'I5691', 'I56946', 'I5720', 'I57258', 'I57309', 'I5764', 'I5775', 'I5781', 'I5806', 'I58295', 'I58301', 'I5856', 'I588250', 'I58827', 'I5891', 'I58927', 'I58930', 'I58939', 'I59078', 'I591622', 'I5924', 'I592464', 'I5933', 'I593411', 'I593441', 'I5956', 'I596', 'I596205', 'I5966', 'I5970', 'I598', 'I59839', 'I5992', 'I59943', 'I60207', 'I60212', 'I60223', 'I6026', 'I602811', 'I6038', 'I603849', 'I603853', 'I6054', 'I60548', 'I6057', 'I6058', 'I606396', 'I6064', 'I6069', 'I60819', 'I61148', 'I612', 'I6129', 'I6130', 'I613391', 'I6135', 'I61381', 'I6142', 'I6146', 'I618060', 'I618278', 'I618371', 'I6185', 'I618597', 'I620', 'I6205', 'I6211', 'I6218', 'I6227', 'I623033', 'I623400', 'I62356', 'I62372', 'I62400', 'I62427', 'I6313', 'I6373', 'I637366', 'I6375', 'I638596', 'I6387', 'I639464', 'I640062', 'I6404', 'I6406', 'I641465', 'I6448', 'I645', 'I6468', 'I6470', 'I6472', 'I6536', 'I6574', 'I6579', 'I658', 'I6581', 'I6582', 'I6585', 'I659476', 'I662411', 'I6628', 'I6672', 'I6676', 'I66887', 'I6691', 'I6694', 'I66981', 'I6703', 'I67108', 'I6711', 'I6719', 'I6728', 'I6750', 'I6754', 'I6759', 'I6782', 'I6802', 'I6809', 'I68091', 'I68099', 'I6813', 'I68139', 'I68149', 'I68244', 'I6832', 'I6835', 'I68442', 'I6845', 'I684879', 'I6851', 'I6873', 'I6876', 'I6878', 'I6883', 'I689', 'I6901', 'I6902', 'I6904', 'I69120', 'I6915', 'I6916', 'I6918', 'I6922', 'I692620', 'I6932', 'I6960', 'I6963', 'I6972', 'I69749', 'I6980', 'I6984', 'I700810', 'I703', 'I704', 'I7052', 'I70589', 'I70598', 'I70599', 'I709271', 'I711043', 'I7145', 'I71535', 'I719872', 'I7213', 'I72143', 'I72210', 'I7226', 'I723', 'I72302', 'I7233', 'I7238', 'I7242', 'I7243', 'I7247', 'I725', 'I7258', 'I72625', 'I72962', 'I72965', 'I7299', 'I73', 'I73032', 'I73056', 'I7315', 'I733', 'I734064', 'I73494', 'I73645', 'I73689', 'I7393', 'I7396', 'I7405', 'I7407', 'I7417', 'I743', 'I7454', 'I7456', 'I74667', 'I746741', 'I7476', 'I7486', 'I748794', 'I749207', 'I7512', 'I7514', 'I7518', 'I7531', 'I7597', 'I7617', 'I7623', 'I762595', 'I762817', 'I763096', 'I763098', 'I763100', 'I7646', 'I7676', 'I7715', 'I77492', 'I77655', 'I7804', 'I7812', 'I7824', 'I7891', 'I7895', 'I797195', 'I7975', 'I797541', 'I797629', 'I797631', 'I797633', 'I797635', 'I797752', 'I7980', 'I798220', 'I798222', 'I798224', 'I798226', 'I798228', 'I798230', 'I798232', 'I798262', 'I798264', 'I798266', 'I798268', 'I798279', 'I798286', 'I798288', 'I798290', 'I798292', 'I798294', 'I798302', 'I798304', 'I798306', 'I798361', 'I798372', 'I7984', 'I798444', 'I7994', 'I8004', 'I8013', 'I801760', 'I802624', 'I8031', 'I804179', 'I804187', 'I807219', 'I8091', 'I8120', 'I8132', 'I8134', 'I8152', 'I8163', 'I816346', 'I8175', 'I8183', 'I819911', 'I82000', 'I82003', 'I82122', 'I82728', 'I828529', 'I8308', 'I83099', 'I83156', 'I8328', 'I83367', 'I83373', 'I8339', 'I83553', 'I8356', 'I83818', 'I83947', 'I8410', 'I84108', 'I847083', 'I84815', 'I84857', 'I84990', 'I8514', 'I8536', 'I854930', 'I854932', 'I854934', 'I854936', 'I854938', 'I854940', 'I854942', 'I854944', 'I854946', 'I854948', 'I854950', 'I854952', 'I854954', 'I854956', 'I854958', 'I854960', 'I854962', 'I854964', 'I854966', 'I854968', 'I854970', 'I854972', 'I854974', 'I8570', 'I85762', 'I85783', 'I857921', 'I857974', 'I858068', 'I8588', 'I8589', 'I8591', 'I8597', 'I86009', 'I8602', 'I8604', 'I8610', 'I8611', 'I861634', 'I8629', 'I8638', 'I8640', 'I864701', 'I8686', 'I8691', 'I8703', 'I8704', 'I8727', 'I8745', 'I8754', 'I87636', 'I877015', 'I8782', 'I8785', 'I8787', 'I88014', 'I880350', 'I88249', 'I8825', 'I8887', 'I8896', 'I89013', 'I892507', 'I892539', 'I8928', 'I8948', 'I89767', 'I89785', 'I89821', 'I89903', 'I89905', 'I8998', 'I9000', 'I90120', 'I901620', 'I901624', 'I901628', 'I901631', 'I901633', 'I901636', 'I90176', 'I90402', 'I9143', 'I9230', 'I92972', 'I9346', 'I9384', 'I9449', 'I9524', 'I9525', 'I9528', 'I9601', 'I9641', 'I9789', 'I9793', 'I9796', 'I9853', 'I9863', 'I9873', 'I99', 'I992657', 'I993449', 'I9945', 'I9947', 'I9949', 'I995869', 'I9997', 'DIASTOLIC', 'SYSTOLIC', 'PULSE', 'TEMPERATURE', 'PULSE OXIMETRY', 'RESPIRATIONS', 'BMI_CLEAN', 'AGE']\n",
    "\n",
    "directory = 'VUMC_covid/'\n",
    "parent_dir = './result_correct/'\n",
    "path = os.path.join(parent_dir, directory)\n",
    "\n",
    "if not os.path.exists(parent_dir):\n",
    "    os.mkdir(parent_dir)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature importance plot\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "top = cm.get_cmap('Oranges_r', 128)\n",
    "bottom = cm.get_cmap('Blues', 128)\n",
    "newcolors = np.vstack((top(np.linspace(0, 1, 128)), bottom(np.linspace(0, 1, 128))))\n",
    "newcmp = ListedColormap(newcolors, name='OrangeBlue')\n",
    "\n",
    "def ABS_SHAP(feature_importance_value, correlation_coeff_value, top, colors):\n",
    "\n",
    "    correlation_coeff_value_ = {}\n",
    "    for key, value in correlation_coeff_value.items():\n",
    "        correlation_coeff_value_[key] = np.mean(value)\n",
    "    corr_df = pd.DataFrame.from_dict(correlation_coeff_value_, orient='index').fillna(0)\n",
    "    corr_df.reset_index(inplace=True)\n",
    "    corr_df.columns  = ['Variable','Corr']\n",
    "    color_assigned = []\n",
    "    for corr in list(corr_df['Corr']):\n",
    "        if not np.isnan(corr):\n",
    "            color_assigned.append(colors[int((corr+1)/2 * len(colors))])\n",
    "        else:\n",
    "            color_assigned.append([1,1,1,1])\n",
    "    corr_df['Sign'] = color_assigned\n",
    "\n",
    "    feature_importance_value_ = {}\n",
    "    feature_importance_value_std = {}\n",
    "    for key, value in feature_importance_value.items():\n",
    "        feature_importance_value_[key] = np.mean(value)\n",
    "        feature_importance_value_std[key] = np.std(value)\n",
    "\n",
    "    feature_importance_std_df = pd.DataFrame.from_dict(feature_importance_value_std, orient='index').fillna(0)\n",
    "    feature_importance_std_df.reset_index(inplace=True)\n",
    "    feature_importance_std_df.columns = ['Variable','SHAP_std']\n",
    "\n",
    "    feature_importance_df = pd.DataFrame.from_dict(feature_importance_value_, orient='index').fillna(0)\n",
    "    feature_importance_df.reset_index(inplace=True)\n",
    "    feature_importance_df.columns = ['Variable','SHAP_abs']\n",
    "\n",
    "    feature_importance_df = feature_importance_df.merge(feature_importance_std_df, left_on='Variable',right_on='Variable',how='inner')\n",
    "\n",
    "    k2 = feature_importance_df.merge(corr_df,left_on = 'Variable',right_on='Variable',how='inner')\n",
    "    k2 = k2.sort_values(by='SHAP_abs',ascending = False).head(top).iloc[::-1]\n",
    "    print(list(k2['Variable']))\n",
    "    colorlist = k2['Sign']\n",
    "    ax = k2.plot.barh(x='Variable',y='SHAP_abs',color = colorlist, figsize=(8,10),legend=False, xerr='SHAP_std', edgecolor='black')\n",
    "    ax.set_xlabel(\"Feature contribution [SHAP Values].\")\n",
    "    ax.set_ylabel(\"Factors\")\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.xaxis.grid(color='gray', linestyle='-.', linewidth=0.5)\n",
    "#     plt.savefig('feature_imp_0.png', dpi=300) \n",
    "#     plt.savefig('feature_imp_0.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    fig, aaxx = plt.subplots(figsize=(0.2, 15))\n",
    "    fig.subplots_adjust(bottom=0.5)\n",
    "    cmap = mpl.colors.ListedColormap(colors)\n",
    "    norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
    "    cb1 = mpl.colorbar.ColorbarBase(aaxx, cmap=cmap,\n",
    "                                norm=norm, orientation='vertical')\n",
    "#     plt.savefig('feature_imp_1.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return k2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. train models on real data 70% and evaluate models using real data 30%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in training (real) data is:  14349\n",
      "The number of features in training (real) data is:  2590\n",
      "Positive vs Negative ratio in training (real) data is: 0.037703\n",
      "\n",
      "The number of records in evaluation (real) data is: 6150\n",
      "The number of features in training (real) data is: 2590\n",
      "Positive vs Negative ratio in evaluation (real) data is: 0.042276\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!! training is starting !!!!!!!!!!!!!!!!!!! \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0369\n",
      "      *** Test on real data AUROC: 0.8021, PRAUC: 0.2162, ACC: 0.8416, PPV: 0.1527, NPV: 0.9799, Sensitivity: 0.6038, Specificity: 0.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I36437', 'I7258', 'I435', 'C761', 'I260101', 'C1010.6', 'C740.11', 'I4124', 'I3992', 'C1009', 'P21', 'I5640', 'P105', 'I36387', 'P62', 'P26', 'I5956', 'P92', 'P23', 'P72', 'P37', 'C465.2', 'I26225', 'PULSE', 'SYSTOLIC', 'TEMPERATURE', 'DIASTOLIC', 'BMI_CLEAN', 'C465', 'RESPIRATIONS', 'AGE', 'PULSE OXIMETRY']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>SHAP_abs</th>\n",
       "      <th>SHAP_std</th>\n",
       "      <th>Corr</th>\n",
       "      <th>Sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>I36437</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.972522</td>\n",
       "      <td>[0.5269414852555195, 0.16405743399722095, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>I7258</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.954926</td>\n",
       "      <td>[0.03137254901960784, 0.22899490504863362, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>I435</td>\n",
       "      <td>0.025573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.926476</td>\n",
       "      <td>[0.03137254901960784, 0.2616025937934229, 0.52...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>C761</td>\n",
       "      <td>0.025604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.980043</td>\n",
       "      <td>[0.5173073953991045, 0.1603520148216767, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>I260101</td>\n",
       "      <td>0.026478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.947695</td>\n",
       "      <td>[0.5558437548247646, 0.17517369152385365, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>C1010.6</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.931030</td>\n",
       "      <td>[0.03137254901960784, 0.25345067160722556, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>C740.11</td>\n",
       "      <td>0.028236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>[0.03137254901960784, 0.23714682723483094, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>I4124</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963879</td>\n",
       "      <td>[0.5365755751119345, 0.16776285317276518, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>I3992</td>\n",
       "      <td>0.028330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>[0.03137254901960784, 0.25345067160722556, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>C1009</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960408</td>\n",
       "      <td>[0.03137254901960784, 0.22899490504863362, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>P21</td>\n",
       "      <td>0.028936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.920340</td>\n",
       "      <td>[0.5943801142504246, 0.18999536822603058, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>I5640</td>\n",
       "      <td>0.031130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.873401</td>\n",
       "      <td>[0.6525551953064691, 0.21232051875868457, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>P105</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.889370</td>\n",
       "      <td>[0.6329164736760846, 0.20481704492820751, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>I36387</td>\n",
       "      <td>0.047194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945439</td>\n",
       "      <td>[0.03137254901960784, 0.23714682723483094, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>P62</td>\n",
       "      <td>0.049859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.943951</td>\n",
       "      <td>[0.5654778446811796, 0.17887911069939788, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>P26</td>\n",
       "      <td>0.055358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.950150</td>\n",
       "      <td>[0.5558437548247646, 0.17517369152385365, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>I5956</td>\n",
       "      <td>0.062212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944789</td>\n",
       "      <td>[0.03137254901960784, 0.24529874942102825, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>P92</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943661</td>\n",
       "      <td>[0.03137254901960784, 0.24529874942102825, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>P23</td>\n",
       "      <td>0.065336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937232</td>\n",
       "      <td>[0.03137254901960784, 0.25345067160722556, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>P72</td>\n",
       "      <td>0.067542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958373</td>\n",
       "      <td>[0.03137254901960784, 0.22899490504863362, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>P37</td>\n",
       "      <td>0.073825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907951</td>\n",
       "      <td>[0.03137254901960784, 0.2779064381658176, 0.55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>C465.2</td>\n",
       "      <td>0.092843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.951031</td>\n",
       "      <td>[0.5558437548247646, 0.17517369152385365, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>I26225</td>\n",
       "      <td>0.112346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.904582</td>\n",
       "      <td>[0.03137254901960784, 0.2860583603520148, 0.56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>PULSE</td>\n",
       "      <td>0.117189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036474</td>\n",
       "      <td>[0.9439246564767639, 0.968503937007874, 0.9920...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SYSTOLIC</td>\n",
       "      <td>0.140733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226058</td>\n",
       "      <td>[0.7987031032885595, 0.8736452061139416, 0.944...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>TEMPERATURE</td>\n",
       "      <td>0.170933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.186590</td>\n",
       "      <td>[0.9943183572641655, 0.8632391539292883, 0.730...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>DIASTOLIC</td>\n",
       "      <td>0.182592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.741663</td>\n",
       "      <td>[0.8583912305079512, 0.2925428439092172, 0.009...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>BMI_CLEAN</td>\n",
       "      <td>0.185364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485274</td>\n",
       "      <td>[0.4385054809325305, 0.6927281148679945, 0.843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>C465</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.959095</td>\n",
       "      <td>[0.5462096649683496, 0.17146827234830941, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RESPIRATIONS</td>\n",
       "      <td>0.205519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691720</td>\n",
       "      <td>[0.1885132005558129, 0.5022386907518913, 0.740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>AGE</td>\n",
       "      <td>0.206726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563378</td>\n",
       "      <td>[0.33351860429211055, 0.6235602902578354, 0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PULSE OXIMETRY</td>\n",
       "      <td>0.209326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.369215</td>\n",
       "      <td>[0.9921568627450981, 0.6876022850084916, 0.428...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Variable  SHAP_abs  SHAP_std      Corr  \\\n",
       "31          I36437  0.023572       0.0 -0.972522   \n",
       "30           I7258  0.023906       0.0  0.954926   \n",
       "29            I435  0.025573       0.0  0.926476   \n",
       "28            C761  0.025604       0.0 -0.980043   \n",
       "27         I260101  0.026478       0.0 -0.947695   \n",
       "26         C1010.6  0.026978       0.0  0.931030   \n",
       "25         C740.11  0.028236       0.0  0.951020   \n",
       "24           I4124  0.028277       0.0 -0.963879   \n",
       "23           I3992  0.028330       0.0  0.936183   \n",
       "22           C1009  0.028797       0.0  0.960408   \n",
       "21             P21  0.028936       0.0 -0.920340   \n",
       "20           I5640  0.031130       0.0 -0.873401   \n",
       "19            P105  0.036255       0.0 -0.889370   \n",
       "18          I36387  0.047194       0.0  0.945439   \n",
       "17             P62  0.049859       0.0 -0.943951   \n",
       "16             P26  0.055358       0.0 -0.950150   \n",
       "15           I5956  0.062212       0.0  0.944789   \n",
       "14             P92  0.063173       0.0  0.943661   \n",
       "13             P23  0.065336       0.0  0.937232   \n",
       "12             P72  0.067542       0.0  0.958373   \n",
       "11             P37  0.073825       0.0  0.907951   \n",
       "10          C465.2  0.092843       0.0 -0.951031   \n",
       "9           I26225  0.112346       0.0  0.904582   \n",
       "8            PULSE  0.117189       0.0  0.036474   \n",
       "7         SYSTOLIC  0.140733       0.0  0.226058   \n",
       "6      TEMPERATURE  0.170933       0.0 -0.186590   \n",
       "5        DIASTOLIC  0.182592       0.0 -0.741663   \n",
       "4        BMI_CLEAN  0.185364       0.0  0.485274   \n",
       "3             C465  0.188200       0.0 -0.959095   \n",
       "2     RESPIRATIONS  0.205519       0.0  0.691720   \n",
       "1              AGE  0.206726       0.0  0.563378   \n",
       "0   PULSE OXIMETRY  0.209326       0.0 -0.369215   \n",
       "\n",
       "                                                 Sign  \n",
       "31  [0.5269414852555195, 0.16405743399722095, 0.01...  \n",
       "30  [0.03137254901960784, 0.22899490504863362, 0.4...  \n",
       "29  [0.03137254901960784, 0.2616025937934229, 0.52...  \n",
       "28  [0.5173073953991045, 0.1603520148216767, 0.015...  \n",
       "27  [0.5558437548247646, 0.17517369152385365, 0.01...  \n",
       "26  [0.03137254901960784, 0.25345067160722556, 0.5...  \n",
       "25  [0.03137254901960784, 0.23714682723483094, 0.4...  \n",
       "24  [0.5365755751119345, 0.16776285317276518, 0.01...  \n",
       "23  [0.03137254901960784, 0.25345067160722556, 0.5...  \n",
       "22  [0.03137254901960784, 0.22899490504863362, 0.4...  \n",
       "21  [0.5943801142504246, 0.18999536822603058, 0.01...  \n",
       "20  [0.6525551953064691, 0.21232051875868457, 0.01...  \n",
       "19  [0.6329164736760846, 0.20481704492820751, 0.01...  \n",
       "18  [0.03137254901960784, 0.23714682723483094, 0.4...  \n",
       "17  [0.5654778446811796, 0.17887911069939788, 0.01...  \n",
       "16  [0.5558437548247646, 0.17517369152385365, 0.01...  \n",
       "15  [0.03137254901960784, 0.24529874942102825, 0.5...  \n",
       "14  [0.03137254901960784, 0.24529874942102825, 0.5...  \n",
       "13  [0.03137254901960784, 0.25345067160722556, 0.5...  \n",
       "12  [0.03137254901960784, 0.22899490504863362, 0.4...  \n",
       "11  [0.03137254901960784, 0.2779064381658176, 0.55...  \n",
       "10  [0.5558437548247646, 0.17517369152385365, 0.01...  \n",
       "9   [0.03137254901960784, 0.2860583603520148, 0.56...  \n",
       "8   [0.9439246564767639, 0.968503937007874, 0.9920...  \n",
       "7   [0.7987031032885595, 0.8736452061139416, 0.944...  \n",
       "6   [0.9943183572641655, 0.8632391539292883, 0.730...  \n",
       "5   [0.8583912305079512, 0.2925428439092172, 0.009...  \n",
       "4   [0.4385054809325305, 0.6927281148679945, 0.843...  \n",
       "3   [0.5462096649683496, 0.17146827234830941, 0.01...  \n",
       "2   [0.1885132005558129, 0.5022386907518913, 0.740...  \n",
       "1   [0.33351860429211055, 0.6235602902578354, 0.80...  \n",
       "0   [0.9921568627450981, 0.6876022850084916, 0.428...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 14.4x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load the dataset for model training. Here it is real data. 70%\n",
    "## Note: the continuous variables in the loaded files have been clipped (to remove outliers).\n",
    "\n",
    "train_real_data = np.load('./train_raw_correct.npy').astype(np.float)\n",
    "train_real_data_index = np.linspace(0,len(train_real_data)-1,len(train_real_data)).astype('int')\n",
    "random.shuffle(train_real_data_index)\n",
    "train_real_data = train_real_data[train_real_data_index]\n",
    "train_real_label = train_real_data[:,LABEL_INDEX].astype(np.float)\n",
    "train_real_data = np.delete(train_real_data, [LABEL_INDEX]+RACE_COL, axis = 1)\n",
    "print('The number of records in training (real) data is:  %d' % len(train_real_data))\n",
    "print('The number of features in training (real) data is:  %d' % len(train_real_data[0]))\n",
    "print('Positive vs Negative ratio in training (real) data is: %f' % (np.sum(train_real_label)/len(train_real_label)))\n",
    "\n",
    "## load the dataset for model evaluation. Here it is real data. 30%\n",
    "eval_real_data = np.load('./test_raw_correct.npy').astype(np.float)\n",
    "eval_real_data_index = np.linspace(0,len(eval_real_data)-1,len(eval_real_data)).astype('int')\n",
    "# random.shuffle(eval_real_data_index)\n",
    "# eval_real_data = eval_real_data[eval_real_data_index]\n",
    "eval_real_label = eval_real_data[:,LABEL_INDEX].astype(np.float)\n",
    "eval_real_data = np.delete(eval_real_data, [LABEL_INDEX]+RACE_COL, axis=1)\n",
    "print('\\nThe number of records in evaluation (real) data is: %d' % len(eval_real_data))\n",
    "print('The number of features in training (real) data is: %d' % len(eval_real_data[0]))\n",
    "print('Positive vs Negative ratio in evaluation (real) data is: %f' % (np.sum(eval_real_label)/len(eval_real_label)))\n",
    "\n",
    "## model training\n",
    "print('\\n !!!!!!!!!!!!!!!!!!! training is starting !!!!!!!!!!!!!!!!!!! ')\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=0).split(X=train_real_data, y=train_real_label)\n",
    "\n",
    "\n",
    "# ############\n",
    "# # try some candidates here\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [500, 1000],\n",
    "#     'colsample_bytree': [0.7, 0.8],\n",
    "#     'max_depth': [15, 25],\n",
    "#     'num_leaves': [20, 50],\n",
    "#     'reg_alpha': [1.1, 1.3],\n",
    "# #     'reg_lambda': [1.1, 1.3],\n",
    "#     'min_split_gain': [0.3, 0.5],\n",
    "#     'subsample': [0.8, 0.9],\n",
    "#     'subsample_freq': [20]\n",
    "#     }\n",
    "############\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'max_depth': [15],\n",
    "    'num_leaves': [50],\n",
    "    'reg_alpha': [1.1],\n",
    "    'min_split_gain': [0.3],\n",
    "    'subsample': [0.9],\n",
    "    'subsample_freq': [20]\n",
    "    }\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary', num_boost_round=2000, learning_rate=0.01, metric='auc',categorical_feature=CAT_IDX_wo_RACE_label, n_jobs = 20)\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf)\n",
    "gbm = gsearch.fit(X=train_real_data, y=train_real_label)\n",
    "print(\"Best parameters:\\n\")\n",
    "print(gbm.best_params_)\n",
    "\n",
    "y_scores = gbm.predict_proba(eval_real_data)\n",
    "y_scores = y_scores[:,1]\n",
    "auroc = roc_auc_score(y_score=y_scores, y_true=eval_real_label)\n",
    "prauc = average_precision_score(eval_real_label, y_scores)\n",
    "fpr, tpr, threshold_candidate = roc_curve(eval_real_label, y_scores)\n",
    "thres_index = (tpr > RECALL_THRESHOLD).tolist().index(True)\n",
    "thres = threshold_candidate[thres_index]\n",
    "print(\"Threshold for fixing recall as %.2f is %.4f\" % (RECALL_THRESHOLD, thres))\n",
    "pred_y = np.array([(value>=thres)*1.0 for value in y_scores])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(eval_real_label, pred_y).ravel()\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "sens = tp / (tp + fn)\n",
    "spes = tn / (tn + fp)\n",
    "acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"      *** Test on real data AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f\" % (\n",
    "auroc, prauc, acc, ppv, npv, sens, spes))\n",
    "\n",
    "explainer = shap.TreeExplainer(gbm.best_estimator_)\n",
    "shap_df = pd.DataFrame(explainer.shap_values(eval_real_data)[1], columns = COL_LIST)\n",
    "shap_df_abs = abs(shap_df)\n",
    "\n",
    "feature_importance_mean = shap_df_abs.mean(axis=0).sort_values(ascending=False)\n",
    "feature_importance_value = {}\n",
    "for key, value in feature_importance_mean.items():\n",
    "    if key in feature_importance_value.keys():\n",
    "        feature_importance_value[key].append(value)\n",
    "    else:\n",
    "        feature_importance_value[key] = [value]\n",
    "        \n",
    "# feature_importance_std = shap_df_abs.std(axis=0).sort_values(ascending=False)\n",
    "# feature_importance_var = {}\n",
    "# for key, value in feature_importance_std.items():\n",
    "#     if key in feature_importance_var.keys():\n",
    "#         feature_importance_var[key].append(value)\n",
    "#     else:\n",
    "#         feature_importance_var[key] = [value]\n",
    "\n",
    "correlation_coeff_value = {}\n",
    "for key in COL_LIST:\n",
    "    corr_value = np.corrcoef(shap_df[key], eval_real_data[:, COL_LIST.index(key)])[1][0]\n",
    "    if key in correlation_coeff_value.keys():\n",
    "        correlation_coeff_value[key].append(corr_value)\n",
    "    else:\n",
    "        correlation_coeff_value[key] = [corr_value]\n",
    "\n",
    "\n",
    "np.save('./result_correct/r_70_train_r_30_test_correl_coeff_value.npy', correlation_coeff_value)\n",
    "shap_df.to_csv('./result_correct/r_70_train_r_30_test_feature_importance.csv')\n",
    "np.save('./result_correct/r_70_train_r_30_test_y_estimate.npy', y_scores)\n",
    "np.save('./result_correct/r_70_train_r_30_test_y_label.npy', eval_real_label)\n",
    "joblib.dump(gbm.best_estimator_, './result/r_70_train_r_30_test.pkl')\n",
    "\n",
    "ABS_SHAP(feature_importance_value, correlation_coeff_value, 32, newcolors) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. train models on synthetic data 70% and evaluate models using real data 30%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   !!!!!!!!!!!!!!!!!!! iwae training is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0120\n",
      "      *** Test on real data AUROC: 0.6172, PRAUC: 0.0734, ACC: 0.5754, PPV: 0.0589, NPV: 0.9704, Sensitivity: 0.6038, Specificity: 0.5742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0095\n",
      "      *** Test on real data AUROC: 0.5755, PRAUC: 0.0610, ACC: 0.5024, PPV: 0.0504, NPV: 0.9661, Sensitivity: 0.6038, Specificity: 0.4980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0261\n",
      "      *** Test on real data AUROC: 0.5013, PRAUC: 0.0484, ACC: 0.3966, PPV: 0.0417, NPV: 0.9568, Sensitivity: 0.6038, Specificity: 0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean AUROC:  0.5646424840015672 , mean AUPRC:  0.060914507029146296\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! medgan training is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0142\n",
      "      *** Test on real data AUROC: 0.6749, PRAUC: 0.1082, ACC: 0.5946, PPV: 0.0616, NPV: 0.9714, Sensitivity: 0.6038, Specificity: 0.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0034\n",
      "      *** Test on real data AUROC: 0.6960, PRAUC: 0.1308, ACC: 0.7036, PPV: 0.0836, NPV: 0.9759, Sensitivity: 0.6038, Specificity: 0.7080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0175\n",
      "      *** Test on real data AUROC: 0.5597, PRAUC: 0.0584, ACC: 0.4475, PPV: 0.0455, NPV: 0.9618, Sensitivity: 0.6038, Specificity: 0.4406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean AUROC:  0.6435231378694876 , mean AUPRC:  0.09910243649618145\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! medbgan training is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0173\n",
      "      *** Test on real data AUROC: 0.5678, PRAUC: 0.0623, ACC: 0.4834, PPV: 0.0486, NPV: 0.9647, Sensitivity: 0.6038, Specificity: 0.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0059\n",
      "      *** Test on real data AUROC: 0.5573, PRAUC: 0.0568, ACC: 0.4663, PPV: 0.0471, NPV: 0.9634, Sensitivity: 0.6038, Specificity: 0.4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0090\n",
      "      *** Test on real data AUROC: 0.6561, PRAUC: 0.1176, ACC: 0.5906, PPV: 0.0610, NPV: 0.9712, Sensitivity: 0.6038, Specificity: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean AUROC:  0.5937260023507901 , mean AUPRC:  0.07888572793855429\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! emrwgan training is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0119\n",
      "      *** Test on real data AUROC: 0.7175, PRAUC: 0.1448, ACC: 0.7086, PPV: 0.0855, NPV: 0.9763, Sensitivity: 0.6077, Specificity: 0.7131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0153\n",
      "      *** Test on real data AUROC: 0.7278, PRAUC: 0.1712, ACC: 0.7730, PPV: 0.1083, NPV: 0.9781, Sensitivity: 0.6038, Specificity: 0.7805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0128\n",
      "      *** Test on real data AUROC: 0.6915, PRAUC: 0.1168, ACC: 0.6837, PPV: 0.0785, NPV: 0.9752, Sensitivity: 0.6038, Specificity: 0.6873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean AUROC:  0.7122674241434853 , mean AUPRC:  0.14427307526662464\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! medwgan training is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0131\n",
      "      *** Test on real data AUROC: 0.6336, PRAUC: 0.0943, ACC: 0.6260, PPV: 0.0667, NPV: 0.9729, Sensitivity: 0.6038, Specificity: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0141\n",
      "      *** Test on real data AUROC: 0.6462, PRAUC: 0.0777, ACC: 0.6106, PPV: 0.0641, NPV: 0.9722, Sensitivity: 0.6038, Specificity: 0.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0152\n",
      "      *** Test on real data AUROC: 0.7331, PRAUC: 0.1528, ACC: 0.7608, PPV: 0.1030, NPV: 0.9777, Sensitivity: 0.6038, Specificity: 0.7677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean AUROC:  0.6709816725436419 , mean AUPRC:  0.10823736459086979\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! dpgan training is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0101\n",
      "      *** Test on real data AUROC: 0.6278, PRAUC: 0.0845, ACC: 0.5641, PPV: 0.0574, NPV: 0.9698, Sensitivity: 0.6038, Specificity: 0.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0092\n",
      "      *** Test on real data AUROC: 0.6841, PRAUC: 0.1059, ACC: 0.6696, PPV: 0.0753, NPV: 0.9747, Sensitivity: 0.6038, Specificity: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "14349\n",
      "2590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.8, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.9, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0034\n",
      "      *** Test on real data AUROC: 0.6613, PRAUC: 0.0899, ACC: 0.6127, PPV: 0.0644, NPV: 0.9723, Sensitivity: 0.6038, Specificity: 0.6131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean AUROC:  0.6577471594619301 , mean AUPRC:  0.09340988443187993\n"
     ]
    }
   ],
   "source": [
    "syn_pos_size = int(np.sum(train_real_label))\n",
    "syn_neg_size = int(len(train_real_label) - np.sum(train_real_label))\n",
    "\n",
    "model_list = ['baseline', 'medgan', 'medbgan', 'emrwgan', 'medwgan', 'dpgan']\n",
    "\n",
    "for model_name in model_list:\n",
    "    pred_result = []\n",
    "#     shap_result = []\n",
    "    correlation_result = []\n",
    "    \n",
    "    real_auroc_result = []\n",
    "    real_prauc_result = []\n",
    "    real_acc_result = []\n",
    "    real_ppv_result = []\n",
    "    real_npv_result = []\n",
    "    real_sens_result = []\n",
    "    real_spes_result = []\n",
    "    \n",
    "    print('\\n   !!!!!!!!!!!!!!!!!!! %s training is starting !!!!!!!!!!!!!!!!!!! ' % model_name)\n",
    "\n",
    "    for run_ in range(RUN_NUM):\n",
    "        \n",
    "        run = run_ + 1\n",
    "        print('\\n ######## Syn dataset %d ######## ' % run)\n",
    "        syn_data_mixed = np.load('./syn_' + model_name + '_' + str(run) + '.npy')\n",
    "        train_syn_label = np.clip(np.round(syn_data_mixed[:,LABEL_INDEX]), 0.0, 1.0).astype(np.float)\n",
    "        train_syn_data = np.delete(syn_data_mixed, [LABEL_INDEX]+RACE_COL, axis=1)\n",
    "#         for idx in CAT_IDX_wo_RACE_label:\n",
    "#             train_syn_data[:, idx] = np.clip(np.round(train_syn_data[:, idx]), 0.0, 1.0)\n",
    "        print(len(train_syn_data))\n",
    "        print(len(train_syn_data[0]))\n",
    "        \n",
    "        gkf = KFold(n_splits=5, shuffle=True, random_state=0).split(X=train_syn_data, y=train_syn_label)\n",
    "        \n",
    "        param_grid = {\n",
    "            'n_estimators': [500],\n",
    "            'colsample_bytree': [0.8],\n",
    "            'max_depth': [15],\n",
    "            'num_leaves': [50],\n",
    "            'reg_alpha': [1.1],\n",
    "            'min_split_gain': [0.3],\n",
    "            'subsample': [0.9],\n",
    "            'subsample_freq': [20]\n",
    "            }\n",
    "\n",
    "        lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary', num_boost_round=2000, learning_rate=0.01, metric='auc',categorical_feature=CAT_IDX_wo_RACE_label, n_jobs = 30)\n",
    "\n",
    "        gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf)\n",
    "        gbm = gsearch.fit(X=train_syn_data, y=train_syn_label)\n",
    "        print(\"Best parameters:\\n\")\n",
    "        print(gbm.best_params_)\n",
    "\n",
    "        y_scores = gbm.predict_proba(eval_real_data)\n",
    "        y_scores = y_scores[:,1]\n",
    "        auroc = roc_auc_score(y_score=y_scores, y_true=eval_real_label)\n",
    "        prauc = average_precision_score(eval_real_label, y_scores)\n",
    "        fpr, tpr, threshold_candidate = roc_curve(eval_real_label, y_scores)\n",
    "        thres_index = (tpr > RECALL_THRESHOLD).tolist().index(True)\n",
    "        thres = threshold_candidate[thres_index]\n",
    "        print(\"Threshold for fixing recall as %.2f is %.4f\" % (RECALL_THRESHOLD, thres))\n",
    "        pred_y = np.array([(value>=thres)*1.0 for value in y_scores])\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(eval_real_label, pred_y).ravel()\n",
    "        ppv = tp / (tp + fp)\n",
    "        npv = tn / (tn + fn)\n",
    "        sens = tp / (tp + fn)\n",
    "        spes = tn / (tn + fp)\n",
    "        acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "        print(\"      *** Test on real data AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f\" % (\n",
    "        auroc, prauc, acc, ppv, npv, sens, spes))\n",
    "        \n",
    "        real_auroc_result.append(auroc)\n",
    "        real_prauc_result.append(prauc)\n",
    "        real_acc_result.append(acc)\n",
    "        real_ppv_result.append(ppv)\n",
    "        real_npv_result.append(npv)\n",
    "        real_sens_result.append(sens)\n",
    "        real_spes_result.append(spes)\n",
    "\n",
    "        explainer = shap.TreeExplainer(gbm.best_estimator_)\n",
    "#         shap_value_list.extend(explainer.shap_values(eval_real_data)[1])\n",
    "        shap_df = pd.DataFrame(explainer.shap_values(eval_real_data)[1], columns = COL_LIST)\n",
    "        shap_df_abs = abs(shap_df)\n",
    "\n",
    "        feature_importance_mean = shap_df_abs.mean(axis=0).sort_values(ascending=False)\n",
    "        feature_importance_value = {}\n",
    "        for key, value in feature_importance_mean.items():\n",
    "            if key in feature_importance_value.keys():\n",
    "                feature_importance_value[key].append(value)\n",
    "            else:\n",
    "                feature_importance_value[key] = [value]\n",
    "        \n",
    "        correlation_coeff_value = {}\n",
    "        for key in COL_LIST:\n",
    "            corr_value = np.corrcoef(shap_df[key], eval_real_data[:, COL_LIST.index(key)])[1][0]\n",
    "            if key in correlation_coeff_value.keys():\n",
    "                correlation_coeff_value[key].append(corr_value)\n",
    "            else:\n",
    "                correlation_coeff_value[key] = [corr_value]\n",
    "\n",
    "        \n",
    "        pred_result.append(y_scores)\n",
    "#         shap_result.append(shap_df)\n",
    "        correlation_result.append(correlation_coeff_value)\n",
    "        joblib.dump(gbm.best_estimator_, './result_correct/' + str(model_name) + '_s_train_r_30_test_' + str(run_) + '.pkl')\n",
    "#         ABS_SHAP(feature_importance_value, correlation_coeff_value, 32, newcolors) \n",
    "        np.save('./result_correct/' + str(model_name) + '_s_train_r_30_test_shap_' + str(run_) + '.npy', shap_df)\n",
    "        \n",
    "    print('   mean AUROC: ', np.mean(real_auroc_result), ', mean AUPRC: ', np.mean(real_prauc_result))\n",
    "    \n",
    "    np.save('./result_correct/' + str(model_name) + '_s_train_r_30_test_correl_coeff.npy', correlation_result)\n",
    "    np.save('./result_correct/' + str(model_name) + '_s_train_r_30_test_y_estimate.npy', pred_result)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. train models on real data 30% and evaluate models using real data 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in training (real) data is:  6150\n",
      "The number of features in training (real) data is:  2590\n",
      "Positive vs Negative ratio in training (real) data is: 0.042276\n",
      "\n",
      "The number of records in evaluation (real) data is: 14349\n",
      "The number of features in training (real) data is: 2590\n",
      "Positive vs Negative ratio in evaluation (real) data is: 0.037703\n",
      "\n",
      " !!!!!!!!!!!!!!!!!!! training is starting !!!!!!!!!!!!!!!!!!! \n",
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.7, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.8, 'subsample_freq': 20}\n",
      "Threshold for fixing recall as 0.60 is 0.0298\n",
      "      *** Test on real data AUROC: 0.7733, PRAUC: 0.1665, ACC: 0.8001, PPV: 0.1091, NPV: 0.9810, Sensitivity: 0.6007, Specificity: 0.8079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 256 is out of bounds for axis 0 with size 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2e90fef9675c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./result_correct/r_30_train_r_70.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mABS_SHAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_importance_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelation_coeff_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;31m################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-f3bb30485749>\u001b[0m in \u001b[0;36mABS_SHAP\u001b[0;34m(feature_importance_value, correlation_coeff_value, top, colors)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Corr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mcolor_assigned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcolor_assigned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 256 is out of bounds for axis 0 with size 256"
     ]
    }
   ],
   "source": [
    "train_real_data = np.load('./test_raw_correct.npy').astype(np.float)\n",
    "train_real_data_index = np.linspace(0,len(train_real_data)-1,len(train_real_data)).astype('int')\n",
    "random.shuffle(train_real_data_index)\n",
    "train_real_data = train_real_data[train_real_data_index]\n",
    "train_real_label = train_real_data[:,LABEL_INDEX].astype(np.float)\n",
    "train_real_data = np.delete(train_real_data, [LABEL_INDEX]+RACE_COL, axis = 1)\n",
    "print('The number of records in training (real) data is:  %d' % len(train_real_data))\n",
    "print('The number of features in training (real) data is:  %d' % len(train_real_data[0]))\n",
    "print('Positive vs Negative ratio in training (real) data is: %f' % (np.sum(train_real_label)/len(train_real_label)))\n",
    "\n",
    "## load the dataset for model evaluation. Here it is real data. 30%\n",
    "eval_real_data = np.load('./train_raw_correct.npy').astype(np.float)\n",
    "eval_real_data_index = np.linspace(0,len(eval_real_data)-1,len(eval_real_data)).astype('int')\n",
    "# random.shuffle(eval_real_data_index)\n",
    "# eval_real_data = eval_real_data[eval_real_data_index]\n",
    "eval_real_label = eval_real_data[:,LABEL_INDEX].astype(np.float)\n",
    "eval_real_data = np.delete(eval_real_data, [LABEL_INDEX]+RACE_COL, axis=1)\n",
    "print('\\nThe number of records in evaluation (real) data is: %d' % len(eval_real_data))\n",
    "print('The number of features in training (real) data is: %d' % len(eval_real_data[0]))\n",
    "print('Positive vs Negative ratio in evaluation (real) data is: %f' % (np.sum(eval_real_label)/len(eval_real_label)))\n",
    "\n",
    "## model training\n",
    "print('\\n !!!!!!!!!!!!!!!!!!! training is starting !!!!!!!!!!!!!!!!!!! ')\n",
    "## metrics for bootstrap\n",
    "real_auroc_result = []\n",
    "real_prauc_result = []\n",
    "real_acc_result = []\n",
    "real_ppv_result = []\n",
    "real_npv_result = []\n",
    "real_sens_result = []\n",
    "real_spes_result = []\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=0).split(X=train_real_data, y=train_real_label)\n",
    "\n",
    "\n",
    "# ############\n",
    "# # try some candidates here\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [500, 1000],\n",
    "#     'colsample_bytree': [0.7, 0.8],\n",
    "#     'max_depth': [15, 25],\n",
    "#     'num_leaves': [20, 50],\n",
    "#     'reg_alpha': [1.1, 1.3],\n",
    "# #     'reg_lambda': [1.1, 1.3],\n",
    "#     'min_split_gain': [0.3, 0.5],\n",
    "#     'subsample': [0.8, 0.9],\n",
    "#     'subsample_freq': [20]\n",
    "#     }\n",
    "# ############\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'max_depth': [15],\n",
    "    'num_leaves': [50],\n",
    "    'reg_alpha': [1.1],\n",
    "    'min_split_gain': [0.3],\n",
    "    'subsample': [0.8],\n",
    "    'subsample_freq': [20]\n",
    "    }\n",
    "\n",
    "# {'colsample_bytree': 0.7, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.8, 'subsample_freq': 20}\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary', num_boost_round=2000, learning_rate=0.01, metric='auc',categorical_feature=CAT_IDX_wo_RACE_label, n_jobs = 30)\n",
    "\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf)\n",
    "gbm = gsearch.fit(X=train_real_data, y=train_real_label)\n",
    "print(\"Best parameters:\\n\")\n",
    "print(gbm.best_params_)\n",
    "\n",
    "y_scores = gbm.predict_proba(eval_real_data)\n",
    "y_scores = y_scores[:,1]\n",
    "auroc = roc_auc_score(y_score=y_scores, y_true=eval_real_label)\n",
    "prauc = average_precision_score(eval_real_label, y_scores)\n",
    "fpr, tpr, threshold_candidate = roc_curve(eval_real_label, y_scores)\n",
    "thres_index = (tpr > RECALL_THRESHOLD).tolist().index(True)\n",
    "thres = threshold_candidate[thres_index]\n",
    "print(\"Threshold for fixing recall as %.2f is %.4f\" % (RECALL_THRESHOLD, thres))\n",
    "pred_y = np.array([(value>=thres)*1.0 for value in y_scores])\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(eval_real_label, pred_y).ravel()\n",
    "ppv = tp / (tp + fp)\n",
    "npv = tn / (tn + fn)\n",
    "sens = tp / (tp + fn)\n",
    "spes = tn / (tn + fp)\n",
    "acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"      *** Test on real data AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f\" % (\n",
    "auroc, prauc, acc, ppv, npv, sens, spes))\n",
    "\n",
    "explainer = shap.TreeExplainer(gbm.best_estimator_)\n",
    "shap_df = pd.DataFrame(explainer.shap_values(eval_real_data)[1], columns = COL_LIST)\n",
    "shap_df_abs = abs(shap_df)\n",
    "\n",
    "feature_importance_mean = shap_df_abs.mean(axis=0).sort_values(ascending=False)\n",
    "feature_importance_value = {}\n",
    "for key, value in feature_importance_mean.items():\n",
    "    if key in feature_importance_value.keys():\n",
    "        feature_importance_value[key].append(value)\n",
    "    else:\n",
    "        feature_importance_value[key] = [value]\n",
    "\n",
    "correlation_coeff_value = {}\n",
    "for key in COL_LIST:\n",
    "    corr_value = np.corrcoef(shap_df[key], eval_real_data[:, COL_LIST.index(key)])[1][0]\n",
    "    if key in correlation_coeff_value.keys():\n",
    "        correlation_coeff_value[key].append(corr_value)\n",
    "    else:\n",
    "        correlation_coeff_value[key] = [corr_value]\n",
    "\n",
    "\n",
    "np.save('./result_correct/r_30_train_r_70_test_correl_coeff_value.npy', correlation_coeff_value)\n",
    "shap_df.to_csv('./result_correct/r_30_train_r_70_test_feature_importance.csv')\n",
    "np.save('./result_correct/r_30_train_r_70_test_y_estimate.npy', y_scores)\n",
    "np.save('./result_correct/r_30_train_r_70_test_y_label.npy', eval_real_label)\n",
    "joblib.dump(gbm.best_estimator_, './result_correct/r_30_train_r_70.pkl')\n",
    "\n",
    "ABS_SHAP(feature_importance_value, correlation_coeff_value, 32, newcolors) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train models on real data 30% and evaluate models using syn data 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of records in training (real) data is:  6150\n",
      "The number of features in training (real) data is:  2590\n",
      "Positive vs Negative ratio in training (real) data is: 0.042276\n",
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found `num_boost_round` in params. Will use it instead of argument\n",
      "categorical_feature keyword has been found in `params` and will be ignored.\n",
      "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=2000, num_boost_round=2000 will be ignored. Current value: num_iterations=2000\n",
      "Best parameters:\n",
      "\n",
      "{'colsample_bytree': 0.7, 'max_depth': 15, 'min_split_gain': 0.3, 'n_estimators': 500, 'num_leaves': 50, 'reg_alpha': 1.1, 'subsample': 0.8, 'subsample_freq': 20}\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! iwae evaluation is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0099\n",
      "      *** Test on syn data AUROC: 0.5078, PRAUC: 0.0398, ACC: 0.4221, PPV: 0.0387, NPV: 0.9637, Sensitivity: 0.6007, Specificity: 0.4150\n",
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0101\n",
      "      *** Test on syn data AUROC: 0.5013, PRAUC: 0.0388, ACC: 0.4078, PPV: 0.0378, NPV: 0.9624, Sensitivity: 0.6007, Specificity: 0.4002\n",
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0093\n",
      "      *** Test on syn data AUROC: 0.4998, PRAUC: 0.0380, ACC: 0.3904, PPV: 0.0367, NPV: 0.9607, Sensitivity: 0.6007, Specificity: 0.3822\n",
      "   mean AUROC:  0.5029696055185845 , mean AUPRC:  0.03886642057569739\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! medgan evaluation is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0158\n",
      "      *** Test on syn data AUROC: 0.7112, PRAUC: 0.0958, ACC: 0.7086, PPV: 0.0758, NPV: 0.9785, Sensitivity: 0.6007, Specificity: 0.7128\n",
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0492\n",
      "      *** Test on syn data AUROC: 0.6756, PRAUC: 0.0715, ACC: 0.6322, PPV: 0.0603, NPV: 0.9759, Sensitivity: 0.6007, Specificity: 0.6335\n",
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0264\n",
      "      *** Test on syn data AUROC: 0.5432, PRAUC: 0.0532, ACC: 0.4470, PPV: 0.0404, NPV: 0.9657, Sensitivity: 0.6007, Specificity: 0.4410\n",
      "   mean AUROC:  0.6433331976819318 , mean AUPRC:  0.07349244347172486\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! medbgan evaluation is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0120\n",
      "      *** Test on syn data AUROC: 0.5195, PRAUC: 0.0395, ACC: 0.4391, PPV: 0.0398, NPV: 0.9651, Sensitivity: 0.6007, Specificity: 0.4327\n",
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0221\n",
      "      *** Test on syn data AUROC: 0.5518, PRAUC: 0.0413, ACC: 0.4940, PPV: 0.0441, NPV: 0.9691, Sensitivity: 0.6007, Specificity: 0.4898\n",
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0232\n",
      "      *** Test on syn data AUROC: 0.6106, PRAUC: 0.0606, ACC: 0.5505, PPV: 0.0496, NPV: 0.9723, Sensitivity: 0.6007, Specificity: 0.5485\n",
      "   mean AUROC:  0.5606016835766848 , mean AUPRC:  0.04712619532902244\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! emrwgan evaluation is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0416\n",
      "      *** Test on syn data AUROC: 0.6910, PRAUC: 0.0919, ACC: 0.6807, PPV: 0.0693, NPV: 0.9776, Sensitivity: 0.6007, Specificity: 0.6839\n",
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0440\n",
      "      *** Test on syn data AUROC: 0.7251, PRAUC: 0.1463, ACC: 0.7122, PPV: 0.0767, NPV: 0.9786, Sensitivity: 0.6007, Specificity: 0.7165\n",
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0359\n",
      "      *** Test on syn data AUROC: 0.6348, PRAUC: 0.0669, ACC: 0.6012, PPV: 0.0557, NPV: 0.9746, Sensitivity: 0.6007, Specificity: 0.6012\n",
      "   mean AUROC:  0.6835971217628399 , mean AUPRC:  0.10170148960427931\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! medwgan evaluation is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0209\n",
      "      *** Test on syn data AUROC: 0.6035, PRAUC: 0.0757, ACC: 0.5531, PPV: 0.0498, NPV: 0.9724, Sensitivity: 0.6007, Specificity: 0.5512\n",
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0178\n",
      "      *** Test on syn data AUROC: 0.5956, PRAUC: 0.0696, ACC: 0.5283, PPV: 0.0473, NPV: 0.9711, Sensitivity: 0.6007, Specificity: 0.5255\n",
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0260\n",
      "      *** Test on syn data AUROC: 0.6721, PRAUC: 0.0959, ACC: 0.6368, PPV: 0.0611, NPV: 0.9761, Sensitivity: 0.6007, Specificity: 0.6383\n",
      "   mean AUROC:  0.6237233596711239 , mean AUPRC:  0.0804264861313697\n",
      "\n",
      "   !!!!!!!!!!!!!!!!!!! dpgan evaluation is starting !!!!!!!!!!!!!!!!!!! \n",
      "\n",
      " ######## Syn dataset 1 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0165\n",
      "      *** Test on syn data AUROC: 0.5143, PRAUC: 0.0387, ACC: 0.4227, PPV: 0.0387, NPV: 0.9637, Sensitivity: 0.6007, Specificity: 0.4158\n",
      "\n",
      " ######## Syn dataset 2 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0074\n",
      "      *** Test on syn data AUROC: 0.5689, PRAUC: 0.0496, ACC: 0.5037, PPV: 0.0449, NPV: 0.9697, Sensitivity: 0.6007, Specificity: 0.4999\n",
      "\n",
      " ######## Syn dataset 3 ######## \n",
      "###### Size of Syn data is 14349\n",
      "###### Num of attributes is 2590\n",
      "Threshold for fixing recall as 0.60 is 0.0095\n",
      "      *** Test on syn data AUROC: 0.5182, PRAUC: 0.0406, ACC: 0.4148, PPV: 0.0382, NPV: 0.9630, Sensitivity: 0.6007, Specificity: 0.4075\n",
      "   mean AUROC:  0.5338014288376317 , mean AUPRC:  0.0429670642434789\n"
     ]
    }
   ],
   "source": [
    "#### model training\n",
    "\n",
    "train_real_data = np.load('./test_raw_correct.npy').astype(np.float)\n",
    "train_real_data_index = np.linspace(0,len(train_real_data)-1,len(train_real_data)).astype('int')\n",
    "random.shuffle(train_real_data_index)\n",
    "train_real_data = train_real_data[train_real_data_index]\n",
    "train_real_label = train_real_data[:,LABEL_INDEX].astype(np.float)\n",
    "train_real_data = np.delete(train_real_data, [LABEL_INDEX]+RACE_COL, axis = 1)\n",
    "print('The number of records in training (real) data is:  %d' % len(train_real_data))\n",
    "print('The number of features in training (real) data is:  %d' % len(train_real_data[0]))\n",
    "print('Positive vs Negative ratio in training (real) data is: %f' % (np.sum(train_real_label)/len(train_real_label)))\n",
    "\n",
    "\n",
    "gkf = KFold(n_splits=5, shuffle=True, random_state=0).split(X=train_real_data, y=train_real_label)\n",
    "\n",
    "#############\n",
    "## try some candidates here\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [500, 1000],\n",
    "#     'colsample_bytree': [0.7, 0.8],\n",
    "#     'max_depth': [15, 25],\n",
    "#     'num_leaves': [20, 50],\n",
    "#     'reg_alpha': [1.1, 1.3],\n",
    "# #     'reg_lambda': [1.1, 1.3],\n",
    "#     'min_split_gain': [0.3, 0.5],\n",
    "#     'subsample': [0.8, 0.9],\n",
    "#     'subsample_freq': [20]\n",
    "#     }\n",
    "#############\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'max_depth': [15],\n",
    "    'num_leaves': [50],\n",
    "    'reg_alpha': [1.1],\n",
    "    'min_split_gain': [0.3],\n",
    "    'subsample': [0.8],\n",
    "    'subsample_freq': [20]\n",
    "    }\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(boosting_type='gbdt',  objective='binary', num_boost_round=2000, learning_rate=0.01, metric='auc',categorical_feature=CAT_IDX_wo_RACE_label, n_jobs = 30)\n",
    "\n",
    "gsearch = GridSearchCV(estimator=lgb_estimator, param_grid=param_grid, cv=gkf)\n",
    "gbm = gsearch.fit(X=train_real_data, y=train_real_label)\n",
    "print(\"Best parameters:\\n\")\n",
    "print(gbm.best_params_)\n",
    "\n",
    "\n",
    "#### model evaluation\n",
    "\n",
    "model_list = ['iwae', 'medgan', 'medbgan', 'emrwgan', 'medwgan', 'dpgan']\n",
    "\n",
    "# model_list = ['emrwgan']\n",
    "\n",
    "for model_name in model_list:\n",
    "    \n",
    "    pred_result = []\n",
    "    label_gt = []\n",
    "    \n",
    "    print('\\n   !!!!!!!!!!!!!!!!!!! %s evaluation is starting !!!!!!!!!!!!!!!!!!! ' % model_name)\n",
    "    \n",
    "    syn_auroc_result = []\n",
    "    syn_prauc_result = []\n",
    "    syn_acc_result = []\n",
    "    syn_ppv_result = []\n",
    "    syn_npv_result = []\n",
    "    syn_sens_result = []\n",
    "    syn_spes_result = []\n",
    "\n",
    "    for run_ in range(RUN_NUM):\n",
    "        \n",
    "        run = run_ + 1\n",
    "        print('\\n ######## Syn dataset %d ######## ' % run)\n",
    "        \n",
    "        syn_data = np.load('./syn_' + model_name + '_' + str(run) + '.npy') ## note: this syn version is not the raw data, but the curated version in block 2. (use the same file names here)\n",
    "        syn_label = np.clip(np.round(syn_data[:,LABEL_INDEX]), 0.0, 1.0).astype(np.float)\n",
    "        syn_data = np.delete(syn_data, [LABEL_INDEX]+RACE_COL, axis=1)\n",
    "#         for idx in CAT_IDX_wo_RACE_label:\n",
    "#             syn_data[:, idx] = np.clip(np.round(syn_data[:, idx]), 0.0, 1.0)    \n",
    "        print('###### Size of Syn data is %d' % len(syn_data))\n",
    "        print('###### Num of attributes is %d' % len(syn_data[0]))\n",
    "        \n",
    "        y_scores = gbm.best_estimator_.predict_proba(syn_data)\n",
    "        y_scores = y_scores[:,1]\n",
    "        auroc = roc_auc_score(y_score=y_scores, y_true=syn_label)\n",
    "        prauc = average_precision_score(syn_label, y_scores)\n",
    "        fpr, tpr, threshold_candidate = roc_curve(syn_label, y_scores)\n",
    "        thres_index = (tpr > RECALL_THRESHOLD).tolist().index(True)\n",
    "        thres = threshold_candidate[thres_index]\n",
    "        print(\"Threshold for fixing recall as %.2f is %.4f\" % (RECALL_THRESHOLD, thres))\n",
    "        pred_y = np.array([(value>=thres)*1.0 for value in y_scores])\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(syn_label, pred_y).ravel()\n",
    "        ppv = tp / (tp + fp)\n",
    "        npv = tn / (tn + fn)\n",
    "        sens = tp / (tp + fn)\n",
    "        spes = tn / (tn + fp)\n",
    "        acc = (tn + tp) / (tn + fp + fn + tp)\n",
    "        print(\"      *** Test on syn data AUROC: %.4f, PRAUC: %.4f, ACC: %.4f, PPV: %.4f, NPV: %.4f, Sensitivity: %.4f, Specificity: %.4f\" % (\n",
    "        auroc, prauc, acc, ppv, npv, sens, spes))   \n",
    "        \n",
    "        syn_auroc_result.append(auroc)\n",
    "        syn_prauc_result.append(prauc)\n",
    "        syn_acc_result.append(acc)\n",
    "        syn_ppv_result.append(ppv)\n",
    "        syn_npv_result.append(npv)\n",
    "        syn_sens_result.append(sens)\n",
    "        syn_spes_result.append(spes)\n",
    "        \n",
    "        pred_result.append(y_scores.tolist())\n",
    "        label_gt.append(syn_label.tolist())\n",
    "    \n",
    "    print('   mean AUROC: ', np.mean(syn_auroc_result), ', mean AUPRC: ', np.mean(syn_prauc_result))\n",
    "    np.save('./result_correct/' + str(model_name) + '_r_30_train_s_test_label_gt.npy', label_gt)\n",
    "    np.save('./result_correct/' + str(model_name) + '_r_30_train_s_test_y_estimate.npy', pred_result)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap: model trained and tested on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ \"Baseline\", \"medGAN\", \"medBGAN\",\"EMR-WGAN\", \"medWGAN\",\"DPGAN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BOOTSTRAPS = 1000\n",
    "# load prediction files saved from prediction stage\n",
    "r_70_r_30 = np.load(\"r_70_train_r_30_test_y_estimate.npy\")\n",
    "r_70_r_30 = pd.DataFrame(r_70_r_30, columns = [\"prediction\"])\n",
    "r_30_r_70 = np.load(\"r_30_train_r_70_test_y_estimate.npy\")\n",
    "r_30_r_70 = pd.DataFrame(r_30_r_70, columns = [\"prediction\"])\n",
    "r_70_gs = np.load(\"r_30_train_r_70_test_y_label.npy\")\n",
    "r_30_gs = np.load(\"r_70_train_r_30_test_y_label.npy\")\n",
    "r_30_gs = pd.DataFrame(r_30_gs, columns = [\"gs\"])\n",
    "r_70_gs = pd.DataFrame(r_70_gs, columns = [\"gs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_submission_r_train_r_test(prediction, gs):\n",
    "    score = []\n",
    "    data = pd.concat([prediction, gs],axis=1)\n",
    "    for boot in range(NUM_BOOTSTRAPS):\n",
    "        temp = {}\n",
    "        # the size of bootstrap sample is the same as the size of the original data\n",
    "        sampled_data = data.sample(n=gs.shape[0], replace=True)\n",
    "        fpr, tpr, thresholds = roc_curve(sampled_data[\"gs\"], sampled_data[\"prediction\"], pos_label=1)\n",
    "        auroc_score = round(auc(fpr, tpr), 4)\n",
    "        #print (boot, auroc_score)\n",
    "        score.append(auroc_score)\n",
    "    # calculate 95% CI\n",
    "    lower_p = 2.5\n",
    "    upper_p =97.5\n",
    "    mean = round(sum(score) / len(score),3)\n",
    "    low = round(np.percentile(score,lower_p),3)\n",
    "    up = round(np.percentile(score,upper_p),3)    \n",
    "    print(f\" {mean}({low},{up})\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on 30% real data and test on 70% real data\n",
    "real_score_30_70 = bootstrap_submission_r_train_r_test(r_30_r_70, r_70_gs)\n",
    "# train on 70% real data and test on 30% real data\n",
    "real_score_70_30 = bootstrap_submission_r_train_r_test(r_70_r_30, r_30_gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap: Model trained on synthetic data and tested on 30% real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BOOTSTRAPS = 1000\n",
    "\n",
    "def bootstrap_submission_s_train_r_30_test(model):\n",
    "    scores = []\n",
    "    # load prediction files saved from previous prediction stage\n",
    "    prediction = np.load(f\"{model}_s_train_r_30_test_y_estimate.npy\").T\n",
    "    prediction = pd.DataFrame(prediction, columns = [\"1\",\"2\",\"3\"])\n",
    "    r_30_gs = np.load(\"r_70_train_r_30_test_y_label.npy\")\n",
    "    r_30_gs = pd.DataFrame(r_30_gs, columns = [\"gs\"])\n",
    "    data = pd.concat([prediction, r_30_gs],axis=1)\n",
    "    for boot in range(NUM_BOOTSTRAPS):\n",
    "        # three runs for each model.\n",
    "        for i in range(1,4):\n",
    "            temp = {}\n",
    "            sampled_data = data[[str(i),\"gs\"]].sample(n=r_30_gs.shape[0], replace=True)\n",
    "            fpr, tpr, thresholds = roc_curve(sampled_data[\"gs\"], sampled_data[str(i)], pos_label=1)\n",
    "            auroc_score = round(auc(fpr, tpr), 4)\n",
    "            #print (boot, auroc_score)\n",
    "            temp[\"Model\"] = model\n",
    "            temp[\"Run\"] = i\n",
    "            temp[\"AUROC\"] = float(auroc_score)\n",
    "            scores.append(temp)\n",
    "    scores = pd.DataFrame(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the boostrapping result\n",
    "res = pd.DataFrame()\n",
    "for model in models:\n",
    "    new = bootstrap_submission_s_train_r_30_test(model)\n",
    "    res = pd.concat([res,new],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 95% CI of each model for each independent run\n",
    "CI = pd.DataFrame()\n",
    "for model in models:\n",
    "    for run in range(1,4):\n",
    "        score_l = list(res[(res[\"Model\"] == model)&(res[\"Run\"] == f\"Run_{run}\")][\"AUROC\"])\n",
    "        mean = round(sum(score_l) / len(score_l),3)\n",
    "        # calculate the 95% CI\n",
    "        lower_p = 2.5\n",
    "        upper_p =97.5\n",
    "        low = round(np.percentile(score_l,lower_p),3)\n",
    "        up = round(np.percentile(score_l,upper_p),3)\n",
    "        print(f\"{model}, run {run}: {mean} [{low},{up}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 95% CI of each model combining three runs\n",
    "CI = pd.DataFrame()\n",
    "for model in models:\n",
    "    score_l = list(res[(res[\"Model\"] == model)][\"AUROC\"])\n",
    "    lower_p = 2.5\n",
    "    upper_p =97.5\n",
    "    mean = round(sum(score_l) / len(score_l),3)\n",
    "    low = round(np.percentile(score_l,lower_p),3)\n",
    "    up = round(np.percentile(score_l,upper_p),3)\n",
    "\n",
    "    print(f\"{model}: {mean}[{low},{up}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap: Model trained on 30% real data and tested on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_BOOTSTRAPS = 1000\n",
    "\n",
    "def bootstrap_submission_r_30_train_s_test(model):\n",
    "    scores = []\n",
    "    #print (predictions)\n",
    "    prediction = np.load(f\"{model}_r_30_train_s_test_y_estimate.npy\").T\n",
    "    prediction = pd.DataFrame(prediction, columns = [\"p_1\",\"p_2\",\"p_3\"])\n",
    "    gs = np.load(f\"{model}_r_30_train_s_test_label_gt.npy\").T\n",
    "    gs = pd.DataFrame(gs, columns = [\"gs_1\",\"gs_2\",\"gs_3\"])\n",
    "    print(gs.shape)\n",
    "    data = pd.concat([prediction, gs],axis=1)\n",
    "    for boot in range(NUM_BOOTSTRAPS):\n",
    "        for i in range(1,4):\n",
    "            temp = {}\n",
    "            # bootstrap 1000 times, each time the bootstrap sample size is the same as the original data\n",
    "            sampled_data = data[[f\"gs_{i}\",f\"p_{i}\"]].sample(n=gs.shape[0], replace=True)\n",
    "            fpr, tpr, thresholds = roc_curve(sampled_data[f\"gs_{i}\"], sampled_data[f\"p_{i}\"], pos_label=1)\n",
    "            auroc_score = round(auc(fpr, tpr), 4)\n",
    "            #print (boot, auroc_score)\n",
    "            temp[\"Model\"] = model\n",
    "            temp[\"Run\"] = i\n",
    "            temp[\"AUROC\"] = float(auroc_score)\n",
    "            scores.append(temp)\n",
    "    scores = pd.DataFrame(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the boostrapping result\n",
    "res = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    new = bootstrap_submission_r_30_train_s_test(model)\n",
    "    res = pd.concat([res,new],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 95% CI of each model for each independent run\n",
    "CI = pd.DataFrame()\n",
    "for model in models:\n",
    "    for run in range(1,4):\n",
    "        score_l = list(res[(res[\"Model\"] == model)&(res[\"Run\"] == f\"Run_{run}\")][\"AUROC\"])\n",
    "        # calculate 95% CI\n",
    "        lower_p = 2.5\n",
    "        upper_p =97.5\n",
    "        mean = round(sum(score_l) / len(score_l),3)\n",
    "        low = round(np.percentile(score_l,lower_p),3)\n",
    "        up = round(np.percentile(score_l,upper_p),3)\n",
    "        \n",
    "        print(f\"{model}, run {run}: {mean} [{low},{up}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 95% CI of each model combining three runs\n",
    "CI = pd.DataFrame()\n",
    "for model in models:\n",
    "    score_l = list(res[(res[\"Model\"] == model)][\"AUROC\"])\n",
    "    lower_p = 2.5\n",
    "    upper_p =97.5\n",
    "    low = round(np.percentile(score_l,lower_p),3)\n",
    "    up = round(np.percentile(score_l,upper_p),3)\n",
    "    mean = round(sum(score_l) / len(score_l),3)\n",
    "    print(f\"{model}: {mean} [{low},{up}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
